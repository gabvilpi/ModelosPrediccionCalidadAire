---
title: "Predicción de la calidad del aire de Madrid mediante modelos supervisados"
subtitle: "
Máster universitario en Ciencia de Datos (Data Science)
Minería de datos y Machine Learning"
author: "Gabriel Villalba Pintado"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 4
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicción de la calidad del aire de Madrid mediante modelos supervisados

## 1. Comprensión de los datos

### 1.1. Carga de datos

#### 1.1.1. Calidad del aire

A continuación se realiza la carga recursiva de los datos de calidad del aire en el periodo 2013-2018. Los ficheros fuente contienen los datos en texto plano con los campos delimitados por un ancho determinado. Las medidas no válidas se inican como "00.00N" y las válidas tienen una letra "V"" después de la medición. Se unificarán los campos "año", "mes" y "dia" en un único campo "fecha". Los datos consolidados se almacenarán en un fichero de texto plano delimitado por comas (CSV).

```{r carga_contaminacion, warning=FALSE, message=FALSE}
# Path datos contaminación "Datos/Contaminación"
setwd("Datos/Contaminación")

# Listamos los ficheros a cargar
ficheros <- list.files(pattern = ".*mo1[3-8].txt")


# Determinamos el ancho de cada campo
anchos <- c(8,2,2,2,2,2,2,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6)

# Determinamos el nombre de las columnas
columnas <- c("estacion","contaminante","tecnica","periodo","anyo","mes","dia","hora1","hora2","hora3","hora4","hora5","hora6","hora7","hora8","hora9","hora10","hora11","hora12","hora13","hora14","hora15","hora16","hora17","hora18","hora19","hora20","hora21","hora22","hora23","hora24")

# Cargamos los datos en un DataFrame. Las medidas no válidas ("00.00N") se sobreescriben con "NA"
for (fichero in ficheros){
  
  # Si el DataSet existe, creamos un DataSet auxiliar para unir los datos
  if (exists("calidadAire")){
    temp_dataset <- read.fwf(file = fichero, widths = anchos, header = FALSE, col.names = columnas, na.strings = c("00.00N"))
    calidadAire <- rbind(calidadAire, temp_dataset)
    rm(temp_dataset)
  }
       
  # Si el DataSet no existe, lo creamos
  if (!exists("calidadAire")){
    calidadAire <- read.fwf(file = fichero, widths = anchos, header = FALSE, col.names = columnas, na.strings = c("00.00N"))
  }
 
}

# Unimos las columnas año, mes y dia en una única columna fecha
calidadAire<-transform(calidadAire, anyo=paste(anyo, mes, dia, sep="/"))
colnames(calidadAire)[5]<-"fecha"
calidadAire<-calidadAire[,!names(calidadAire) %in% c("mes", "dia")]

# Eliminamos la V de los valores válidos de cada medición horaria
for (i in 6:29) {
  calidadAire[,i]<-gsub("V","",calidadAire[,i])
}

# Corregimos el tipo de dato de cada columna
# calidadAire<-transform(calidadAire, estacion=as.factor(estacion), contaminante=as.factor(contaminante), tecnica=as.factor(tecnica), periodo=as.factor(periodo), fecha=as.Date(fecha, format("%y/%m/%d")), hora1=as.numeric(hora1), hora2=as.numeric(hora2), hora3=as.numeric(hora3), hora4=as.numeric(hora4), hora5=as.numeric(hora5), hora6=as.numeric(hora6), hora7=as.numeric(hora7), hora8=as.numeric(hora8), hora9=as.numeric(hora9), hora10=as.numeric(hora10), hora11=as.numeric(hora11), hora12=as.numeric(hora12), hora13=as.numeric(hora13), hora14=as.numeric(hora14), hora15=as.numeric(hora15), hora16=as.numeric(hora16), hora17=as.numeric(hora17), hora18=as.numeric(hora18), hora19=as.numeric(hora19), hora20=as.numeric(hora20), hora21=as.numeric(hora21), hora22=as.numeric(hora22), hora23=as.numeric(hora23), hora24=as.numeric(hora24))

# Corregimos el tipo de dato de cada columna
calidadAire <- transform(calidadAire, estacion=as.factor(estacion), contaminante=as.factor(contaminante), tecnica=as.factor(tecnica), periodo=as.factor(periodo), fecha=as.Date(fecha, format("%y/%m/%d")))
calidadAire[,6:29] <- sapply(calidadAire[,6:29], as.numeric)

# Ordenamos el data frame por fecha, estación y contaminante
calidadAire <- calidadAire[order(calidadAire$fecha, calidadAire$estacion, calidadAire$contaminante),]

# Guardamos los datos
write.csv(calidadAire, file = "calidadAire.csv", row.names = FALSE)

```

#### 1.1.2. Meteorología

En el siguiente trozo de código se procede a realizar la carga recursiva de los ficheros de meteorología. Los ficheros contienen los datos en texto plano con los diferentes campos separados por comas (CSV). Se procederá a eliminar el número de fila y a modificar el nivel de precipitación "Ip" (inapreciable ó <0.01) por el valor 0.05. Los datos consolidados se almacenarán en un fichero CSV.

```{r carga_meteorologia, warning=FALSE, message=FALSE}
# Path datos meteorología "Datos/Clima"
setwd("Datos/Clima")

# Listamos los ficheros a cargar
ficheros <- list.files(pattern = "weather_201[3-8].*.csv")

# Determinamos el nombre de las columnas
columnas <- c("id","altitud","dir","fecha","horaPresMax","horaPresMin","horaRacha","horaTmax","horaTmin","indicativo","nombre","prec","presMax","presMin","provincia","racha","tmax","tmed","tmin","velMedia")

# Determinamos el tipo de dato de cada columna en la lectura del fichero
colClasses = c("character","character","character","Date","character","character","character","character","character","character","character","character","character","character","character","character","character","character","character","character")

# Cargamos los datos en un DataFrame
for (fichero in ficheros){
  
  # Si el DataSet existe, creamos un DataSet auxiliar para unir los datos
  if (exists("clima")){
    temp_dataset <- read.csv(file = fichero, header = TRUE, sep = ",", col.names = columnas, colClasses = colClasses, na.strings = c(""))
    clima <- rbind(clima, temp_dataset)
    rm(temp_dataset)
  }
       
  # Si el DataSet no existe, lo creamos
  if (!exists("clima")){
    clima <- read.csv(file = fichero, header = TRUE, sep = ",", col.names = columnas, colClasses = colClasses, na.strings = c(""))
  }
 
}

# Eliminamos del data frame el indicador de fila
clima <- clima[2:20]

# Sustituimos la medida de precipitación inapreciable (Ip < 0.1) por el valor de 0.05
clima$prec <- gsub("Ip", "0.05", clima$prec)

# Corregimos el tipo de dato de cada columna
clima <- transform(clima, altitud = as.integer(altitud), dir = as.integer(dir), indicativo = as.factor(indicativo), nombre = as.factor(nombre), prec = as.numeric(sub(",", ".", prec)), presMax = as.numeric(sub(",", ".", presMax)), presMin = as.numeric(sub(",", ".", presMin)), provincia = as.factor(provincia), racha = as.numeric(sub(",", ".", racha)), tmax = as.numeric(sub(",", ".", tmax)), tmed = as.numeric(sub(",", ".", tmed)), tmin = as.numeric(sub(",", ".", tmin)), velMedia = as.numeric(sub(",", ".", velMedia)))

# Guardamos los datos
write.csv(clima, file = "clima.csv", row.names = FALSE)

```

#### 1.1.3. Calendario laboral

Por último, se realiza la carga del calendario laboral. Se trata de un fichero en texto plano con los campos separados por punto y coma (CSV). Se procederá a normalizar los campos diaSemana y tipoFestivo. Los datos cargados y normalizados se almacenarán en un fichero CSV.

```{r carga_calendario, warning=FALSE, message=FALSE}
# Path datos meteorología "Datos/Clima"
setwd("Datos/Calendario")

# Listamos los ficheros a cargar
ficheros <- list.files(pattern = "Calendario.*.csv")

# Determinamos el nombre de las columnas
columnas <- c("fecha","diaSemana","tipoDia","tipoFestivo","festividad")

# Cargamos los datos en un DataFrame
for (fichero in ficheros){
  
  # Si el DataSet existe, creamos un DataSet auxiliar para unir los datos
  if (exists("calendario")){
    temp_dataset <- read.csv(file = fichero, header = TRUE, sep = ";", col.names = columnas)
    calendario <- rbind(clima, temp_dataset)
    rm(temp_dataset)
  }
       
  # Si el DataSet no existe, lo creamos
  if (!exists("calendario")){
    calendario <- read.csv(file = fichero, header = TRUE, sep = ";", col.names = columnas)
  }
 
}

# Corregimos el tipo de dato de la columna dia
calendario<-transform(calendario, fecha=as.Date(fecha, format("%d/%m/%Y")))

# Corregimos los niveles de algúnos de los factores
levels(calendario$diaSemana)<-gsub("miercoles", "miércoles", levels(calendario$diaSemana))
levels(calendario$diaSemana)<-gsub("sabado", "sábado", levels(calendario$diaSemana))
levels(calendario$tipoFestivo)<-gsub("Festivo de la comunidad de Madrid", "Festivo de la Comunidad de Madrid", levels(calendario$tipoFestivo))

# Corregimos los niveles vacíos por "laborables"
levels(calendario$tipoDia)<-c("laborable", "domingo", "festivo", "laborable", "sabado")

# Guardamos los datos
write.csv(calendario, file = "calendario.csv", row.names = FALSE)

```

### 1.2. Exploración de los datos

#### 1.2.1. Calidad del aire

```{r exploracion_calidadAire, warning=FALSE, message=FALSE}

contaminante = c("Dióxido de Azufre","Monóxido de Carbono","Monóxido de Nitrógeno","Dióxido de Nitrógeno","Partículas PM2.5","Partículas PM10","Óxidos de Nitrógeno","Ozono","Tolueno","Benceno","Etilbenceno","Hidrocarburos totales
(hexano)","Metano","Hidrocarburos
no metánicos (hexano)")

j=1

# Boxplot mediciones de calidadAire
for (i in levels(calidadAire$contaminante)){
  boxplot(calidadAire[calidadAire$contaminante==i,6:29], main=contaminante[j], outline = FALSE)
  j=j+1
}

```

#### 1.2.2. Meteorología

```{r exploracion_clima, warning=FALSE, message=FALSE}
# str()
str(clima)

# summary()
summary(clima)

# Gráficos
library(ggplot2)

# Precipitaciones
ggplot(data = clima, aes(fecha, prec)) + geom_line() + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Precipitaciones en 2018 (mm)")

# Presión atmosférica
ggplot(data = clima, aes(fecha)) + geom_line(aes(y = presMax, colour = "presMax")) + geom_line(aes(y = presMin, colour = "presMin")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Presión max y min en 2018 (hPa)")

# Temperatura
ggplot(data = clima, aes(fecha)) + geom_line(aes(y = tmax, colour = "tmax")) + geom_line(aes(y = tmed, colour = "tmed")) + geom_line(aes(y = tmin, colour = "tmin")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Temperatura máxima, media y mínima en 2018 (ºC)")

# Viento
ggplot(data = clima, aes(fecha)) + geom_line(aes(y = racha, colour = "racha")) + geom_line(aes(y = velMedia, colour = "velMedia")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Velocidad máxima y media del viento en 2018 (m/s)")

```

#### 1.2.3. Calendario laboral

```{r exploracion_calendario, warning=FALSE, message=FALSE}
# str()
str(calendario)

# summary()
summary(calendario)

```

### 1.3. Preparación de los datos

#### 1.3.1. Seleccionar e integrar los datos

A continuación se seleccionan los datos deseados para constuir el modelo de predicción de la calidad del aire. Los datos seleccionados se integrarán en un nuevo data frame uniendo todos los datos de una misma fecha. 

Del data frame "calidadAire" se seleccionarán los datos correspondientes a la fecha de la medida, la estación, el contaminante medido y las 24 medidas horarias. Del data frame "clima" se seleccionará la fecha y los datos de medidas de precipitación, presión máxima y mínima, temperatura máxima, mínima y media, y velocidad media y máxima del viento. Por último, del data frame "calendario" se seleccionará la fecha y si ese dia es fesitivo o no.

```{r seleccionar_integrar, warning=FALSE, message=FALSE}

# Seleccionamos los datos del data frame calidadAire y creamos un data frame nuevo
datos <- calidadAire[,c("estacion","fecha","contaminante","hora1","hora2","hora3","hora4","hora5","hora6","hora7","hora8","hora9","hora10","hora11","hora12","hora13","hora14","hora15","hora16","hora17","hora18","hora19","hora20","hora21","hora22","hora23","hora24")]

# Uniremos los data frames como data table
require(data.table)
setDT(datos)

# Unimos los datos seleccionados del data frame clima según la fecha de las mediciones
datos<-datos[clima[,c("fecha","prec","presMax","presMin","tmax","tmed","tmin","racha","velMedia")], on = "fecha"]

# Unimos los datos seleccionados del data frame calendario según la fecha de las mediciones
datos<-datos[calendario[calendario$fecha<'2019-01-01',c("fecha","tipoDia")], on = "fecha"]

# Reconvertimos la data table en data frame
datos<-as.data.frame(datos)

```

Una vez integrados los datos en el data frame "datos" se realizarán las siguientes transformaciones:

- Se sustituye el nombre del campo "festivo" por "laborable" y lo codificamos como 0|1 (festivo = 0, sabado = 0, domingo = 1, laborable = 1)

```{r codificación_laborable, warning=FALSE, message=FALSE}

# Sustituimos el nombre del campo "festivo" por "laborable"
colnames(datos)[36]<-"laborable"

# Codificamos el campo laborable
levels(datos$laborable)<-c(1,0,0,0)

# Cambiamos el tipo de dato del campo laborable a numérico
datos$laborable<-as.numeric(levels(datos$laborable)[datos$laborable])

```

- Se imputa a los valores perdidos (NA) el valor de la media aritmética del resto de valores observados

```{r imputación_valores, message=FALSE, warning=FALSE}

for (i in levels(datos$contaminante)) {
  for (j in levels(datos$estacion)) {
    for (k in colnames(datos)[4:35]) {
      temp<-is.na(datos[[k]])
      if (nrow(datos[temp & datos$contaminante==i & datos$estacion==j,][k]) != 0) {
        datos[temp & datos$contaminante==i & datos$estacion==j,][k] <- mean(data.matrix(datos[datos$contaminante==i & datos$estacion==j,][k]), na.rm = TRUE)
      }
      rm(temp)
    }
  }
}

# Guardamos los datos
write.csv(datos, file = "datos.csv", row.names = FALSE)

```

Realizamos una nueva exploración de los datos una vez imputado a los valores perdidos (NA) el valor de la media aritmética del resto de valores observados

```{r exploración_datos, message=FALSE, warning=FALSE}
j=1

# Boxplot datos contaminación
for (i in levels(datos$contaminante)){
  boxplot(datos[datos$contaminante==i,4:27], main=contaminante[j], outline = FALSE)
  j=j+1
}

# Gráficos
library(ggplot2)

# Precipitaciones
ggplot(data = datos, aes(fecha, prec)) + geom_line() + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Precipitaciones en 2018 (mm)")

# Presión atmosférica
ggplot(data = datos, aes(fecha)) + geom_line(aes(y = presMax, colour = "presMax")) + geom_line(aes(y = presMin, colour = "presMin")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Presión max y min en 2018 (hPa)")

# Temperatura
ggplot(data = datos, aes(fecha)) + geom_line(aes(y = tmax, colour = "tmax")) + geom_line(aes(y = tmed, colour = "tmed")) + geom_line(aes(y = tmin, colour = "tmin")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Temperatura máxima, media y mínima en 2018 (ºC)")

# Viento
ggplot(data = datos, aes(fecha)) + geom_line(aes(y = racha, colour = "racha")) + geom_line(aes(y = velMedia, colour = "velMedia")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Velocidad máxima y media del viento en 2018 (m/s)")
```

- Se incluye una columna con la media y otra con el máximo de las mediciones horarias de contaminación en esa estación para cada día

```{r media_y_max_diario_contaminación}

# Calculamos el nivel medio de contaminación en cada estación para cada día
datos <- transform(datos, media = rowMeans(data.matrix(datos[,4:27])))

# Cargamos la librería matrixStats para usar la función rowMaxs
library(matrixStats)

# Calculamos el nivel máximo de contaminación en cada estación para cada día
datos <- transform(datos, maximo = rowMaxs(data.matrix(datos[,4:27])))

# Reordenamos las columnas
datos<-datos[,c("estacion","fecha","contaminante","hora1","hora2","hora3","hora4","hora5","hora6","hora7","hora8","hora9","hora10","hora11","hora12","hora13","hora14","hora15","hora16","hora17","hora18","hora19","hora20","hora21","hora22","hora23","hora24","media","maximo","prec","presMax","presMin","tmax","tmed","tmin","racha","velMedia","laborable")]

# Guardamos los datos
write.csv(datos, file = "datos.csv", row.names = FALSE)

```

- Se normalizan todas las medidas mediante *z-score* en un nuevo dataframe "datosNorm": 
$$z_i = \frac{x_i - \overline{x}}{\sigma}$$

```{r normalización, message=FALSE, warning=FALSE}

datosNorm <- datos

for (i in levels(datosNorm$contaminante)) {
  for (j in levels(datosNorm$estacion)) {
    if (nrow(datosNorm[datosNorm$contaminante==i & datosNorm$estacion==j, 4:35]) != 0) {
      datosNorm[datosNorm$contaminante==i & datosNorm$estacion==j, 4:35] <- scale(datosNorm[datosNorm$contaminante==i & datosNorm$estacion==j, 4:35], center = TRUE, scale = TRUE) 
    }
  }
}

# Guardamos los datos
write.csv(datosNorm, file = "datos_normalizados.csv", row.names = FALSE)

```

- Revisamos la correlación entre la media diaria de contaminación y el resto de atributos climatológicos y si el día es laboral o no

```{r correlación, message=FALSE, warning=FALSE}

j=1

for (i in levels(datosNorm$contaminante)) {
  print(paste0("Correlación de atributos para el contamiante: ", contaminante[j]))
  print(cor(datosNorm[datosNorm$contaminante==i,28:37])[,"media"])
  cat("\n")
  j=j+1
}

```

### 1.4. Caracterización del clima de Madrid

El clima de la ciudad de Madrid según la clasificación climática de Köppen es clima templado con verano seco y caluroso (Csa).

A continuación se muestran los valores climatológicos medios para cada estación del año según los datos del periodo 2013-2018.

```{r Caracterización_estaciones, message=FALSE, warning=FALSE}

# primavera (20/03 -20/06)
cat("Climatología en los meses de primavera:\n")
print(colMeans(datos[format(datos$fecha,"%m-%d")>='03-20'&format(datos$fecha,"%m-%d")<='06-20',c("prec","presMax","presMin","racha","tmax","tmed","tmin","velMedia")], na.rm = TRUE))

# verano (21/06 - 22/09)
cat("\nclimatología en los meses de verano:\n")
print(colMeans(datos[format(datos$fecha,"%m-%d")>='06-21'&format(datos$fecha,"%m-%d")<='09-22',c("prec","presMax","presMin","racha","tmax","tmed","tmin","velMedia")], na.rm = TRUE))

# otoño (23/09 - 20/12)
cat("\nClimatología en los meses de otoño:\n")
print(colMeans(datos[format(datos$fecha,"%m-%d")>='09-23'&format(datos$fecha,"%m-%d")<='12-20',c("prec","presMax","presMin","racha","tmax","tmed","tmin","velMedia")], na.rm = TRUE))

# invierno (21/12 - 19/03)
cat("\nClimatología en los meses de invierno:\n")
print(colMeans(datos[(format(datos$fecha,"%m-%d")>='12-21'&format(datos$fecha,"%m-%d")<='12-31') | (format(datos$fecha,"%m-%d")>='01-01' & format(datos$fecha,"%m-%d")<='03-19'),c("prec","presMax","presMin","racha","tmax","tmed","tmin","velMedia")], na.rm = TRUE))

```

A continuación se muestra un gráfico temporal con los datos de temperatura y precipitaciones a lo largo del año 2018:

```{r caracterización_precipitaciones, message=FALSE, warning=FALSE}

# Gráficos
library(ggplot2)

# Precipitaciones y temperatura
ggplot(data = datos, aes(fecha, prec)) + geom_line(aes(y = prec, colour = "prec")) + geom_line(aes(y = tmed, colour = "tmed")) + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2018-01-01','2018-12-31'))) + ggtitle("Precipitaciones (mm) y temperatura (ºC) en 2018")

```

Como se puede observar en el gráfico, el clima de Madrid a lo largo del año se caracteriza por una sequia estival que se corresponde con las temperaturas más elevadas.

A continuación se muestra el nivel de lluvias acumulado (mm) durante los meses del año 2018:

```{r caracterización_precipitaciones_acumulado, message=FALSE, warning=FALSE}

# Precipitaciones acumulado
ggplot(data = clima, aes(x = as.Date(cut(clima$fecha, breaks = "month")), y = prec)) + stat_summary(fun.y = cumsum, geom = "bar") + scale_x_date(date_breaks = "1 month", date_labels = "%m", limits=as.Date(c('2017-12-01','2018-12-31'))) + xlab("Fecha") + ylab("Prestaciones")

```

Durante el año 2018, el mes de mayor acumulación de lluvias fue marzo seguido de abril y mayo.

### 1.5. Modelo de predicción de la calidad del aire de Madrid

En los modelos de series temporales, los datos se recogen de manera secuencial durante el paso del tiempo.

Estos modelos son de tipo supervisado, por lo que necesitan de una variable objetivo Y y un predictor X.

Para conseguir esto, es necesario transformar la serie temporal (array de observaciones) en una nueva serie en la que se agrupen k observaciones consecutivas desde el momento t-k hasta t de forma que podamos entrenar al modelo con las k-1 observaciones anteriores a t como predictor X y la observación de t como variable objetivo Y.

Por lo tanto, para nuestro modelo elegiremos un contaminante a predecir, tomaremos sus observaciones y las almacenaremos como una serie temporal. A continuación estableceremos el número de k de observaciones que agruparemos, por ejemplo 7 días y entrenaremos el modelo con las k-1 primeras observaciones como predictor X y la observación k como variable objetivo Y.

```{r carga_datos, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

# Carga del fichero "datos.csv" con los datos ya preprocesados

# Establecemos el nombre de las columnas
columnas <- c("estacion","fecha","contaminante","hora1","hora2","hora3","hora4","hora5","hora6","hora7","hora8","hora9","hora10","hora11","hora12","hora13","hora14","hora15","hora16","hora17","hora18","hora19","hora20","hora21","hora22","hora23","hora24","media","maximo","prec","presMax","presMin","tmax","tmed","tmin","racha","velMedia","laborable")

datos <- read.csv(file = "datos.csv", header = TRUE, sep = ",", col.names = columnas)

# Establecemos el tipo de dato de cada columna
datos$estacion <- as.factor(datos$estacion)
datos$fecha<-as.Date(datos$fecha, format("%Y-%m-%d"))
datos$contaminante <- as.factor(datos$contaminante)

```

```{r preparar_datos, message=FALSE, warning=FALSE}

preparar_datos <- function(c, predictores) {
  
  # c: Código del contaminante cuya medida seleccionar
  # predictores: 1 sólo medidas de contaminación, 2 medidas de contaminación y climatología, 3 medidas de contaminación, climatología y calendario laboral 
  
  if (is.null(c)) stop("El parámetro c (código de contaminante) es obligatorio.")
  if (is.null(predictores)) stop("El parámetro preditores es obligatorio.")
  
  if (predictores == 1) {
    
    # Sólo se utilizan los datos de medidas de contaminación para el contaminante c
    
    # Almacenamos las observaciones del contaminante c como series temporales en X e Y siendo Y[i] la siguiente medición a X[i]
    X <- vector()
    
    for (estacion in levels(datos$estacion)) {
      X<-c(X,datos[datos$contaminante==c&datos$estacion==estacion,"maximo"])
    }
    
    Y <- X[-1]
    X <- X[-length(X)]
    
    # Separamos X en un set de entrenamiento y otro de test (80% y 20% respectivamente)
    sample<-c(1:(0.8*length(X)))
        
    X_train <- X[sample]
    Y_train <- Y[sample]
        
    X_test <- X[-sample]
    Y_test <- Y[-sample]
    
  } else if (predictores == 2) {
    
    # Se utilizan los datos de medidas de contaminación y las medidas climatológicas
    
    # Almacenamos las observaciones del contaminante c como series temporales en X e Y siendo Y[i,] las siguientes mediciones a X[i,]
    X <- data.frame()
    
    for (estacion in levels(datos$estacion)) {
      X <- rbind(X,datos[datos$contaminante==c&datos$estacion==estacion,c("maximo","prec","presMax","presMin","tmax","tmed","tmin", "racha","velMedia")])
    }
    
    Y <- X[-1,"maximo"]
    X <- X[-length(X),]
    
    # Separamos X en un set de entrenamiento y otro de test (80% y 20% respectivamente)
    sample<-c(1:(0.8*nrow(X)))
        
    X_train <- X[sample,]
    Y_train <- Y[sample]
        
    X_test <- X[-sample,]
    Y_test <- Y[-sample]
    
  } else if (predictores == 3) {
    
    # Se utilizan los datos de medidas de contaminación, las medidas climatológicas y el calendario laboral
    
    # Almacenamos las observaciones del contaminante c como series temporales en X e Y siendo Y[i,] las siguientes mediciones a X[i,]
    X <- data.frame()
    
    for (estacion in levels(datos$estacion)) {
      X <- rbind(X,datos[datos$contaminante==c&datos$estacion==estacion,c("maximo","prec","presMax","presMin","tmax","tmed","tmin", "racha","velMedia","laborable")])
    }
    
    Y <- X[-1,"maximo"]
    X <- X[-length(X),]
    
    # Separamos X en un set de entrenamiento y otro de test (80% y 20% respectivamente)
    sample<-c(1:(0.8*nrow(X)))
        
    X_train <- X[sample,]
    Y_train <- Y[sample]
        
    X_test <- X[-sample,]
    Y_test <- Y[-sample]
    
  }
  
  returnList <- list("X_train" = X_train, "Y_train" = Y_train, "X_test" = X_test, "Y_test" = Y_test)
  return(returnList)
  
  }

```

```{r modelo_lstm, message=FALSE, warning=FALSE}

crear_modelo_lstm <- function(batch_size, units) {
  
  # Importamos la librería keras para crear el modelo
  library(keras)
  
  # Destroys the current TF graph and creates a new one. Useful to avoid clutter from old models / layers.
  k_clear_session()
  
  # Creamos un modelo secuencial como una pila lineal de capas
  modelo <- keras_model_sequential()
  
  # Añadimos las capas al modelo
  modelo %>%
    layer_lstm(units = units, batch_input_shape = c(batch_size, 1, n), 
               return_sequences = TRUE, stateful=TRUE) %>% 
    layer_lstm(units = units, return_sequences = TRUE, stateful=TRUE) %>% 
    layer_lstm(units = units, return_sequences = FALSE, stateful=TRUE) %>% 
    layer_dense(units = 1)
  
  # Compilamos el modelo
  modelo %>% compile(loss = 'mean_squared_error', optimizer = 'RMSprop')
  
  return(modelo)

}

```

```{r train_lstm, message=FALSE, warning=FALSE}

entrenar_modelo_lstm <- function(modelo, batch_size, epochs) {
  
  # Determinamos el número de épocas
  #epochs = 1
  
  if(typeof(X_train)=="list") {
    #X_train contiene varias columnas
    
    # Truncamos las observaciones de X_train e Y_train para coincidir con el batch_size
    num = batch_size*as.integer(nrow(X_train)/batch_size)
  
    # Convertimos el data frame X_train en una matriz
    X_train <- data.matrix(X_train[1:num,]) #Si X_train contiene varias columnas
  
    # Redimensionamos la matrix X_train
    dim(X_train) <- c(dim(X_train)[1],1,dim(X_train)[2])
  
  } else {
    # X_train es un Array
  
    # Truncamos las observaciones de X_train e Y_train para coincidir con el batch_size
    num = batch_size*as.integer(length(X_train)/batch_size)
  
    # Convertimos el data frame X_train en una matriz
    X_train <- data.matrix(X_train[1:num]) #Si X_train es un Array
  
    # Redimensionamos la matrix X_train
    dim(X_train) <- c(dim(X_train)[1],1,dim(X_train)[2])

  }
  
  modelo %>% fit(X_train, Y_train[1:num], batch_size = batch_size, epochs = epochs, verbose = 1, shuffle = FALSE)
  
}

```

```{r test_lstm, message=FALSE, warning=FALSE}

predicciones_modelo_lstm <- function(modelo, batch_size) {
  
  if(typeof(X_test)=="list") {
    #X_test contiene varias columnas
    
    # Truncamos las observaciones de X_test e Y_test para coincidir con el batch_size
    num = as.integer(nrow(X_test)/batch_size)*batch_size
  
    # Convertimos el data frame X_train en una matriz
    X_test <- data.matrix(X_test[1:num,]) #Si X_test contiene varias columnas
  
    # Redimensionamos la matrix X_train
    dim(X_test) <- c(dim(X_test)[1],1,dim(X_test)[2])
  
  } else {
    # X_test es un Array
  
    # Truncamos las observaciones de X_test e Y_test para coincidir con el batch_size
    num = as.integer(length(X_test)/batch_size)*batch_size
  
    # Convertimos el data frame X_test en una matriz
    X_test <- data.matrix(X_test[1:num]) #Si X_test es un Array
  
    # Redimensionamos la matrix X_test
    dim(X_test) <- c(dim(X_test)[1],1,dim(X_test)[2])
  
  }
  
  Y_pred <- modelo %>% predict(X_test, batch_size = batch_size)
  
  return(Y_pred)
  
}

```

```{r evaluacion_lstm}

evaluar_modelo_lstm <- function() {
  
  return(sqrt(mean((Y_pred - Y_test[1:length(Y_pred)])^2)))
  
  # library(ggplot2)
  # 
  # pos <- c(1:length(Y_pred))
  # result <- cbind(pos, Y_test[1:length(Y_pred)])
  # result <- cbind(result, Y_pred)
  # colnames(result) <- c("pos","Y_test","Y_pred")
  # result <- as.data.frame(result)
  # 
  # ggplot(data = result, aes(pos)) + geom_line(aes(y = Y_test, colour = "Y_test")) + geom_line(aes(y = Y_pred, colour = "Y_pred"))
  
}

```

```{r model_bench, message=FALSE, warning=FALSE}

c = 8 # Dióxido de nitrógeno
predictores = c(1,2,3) # Las variables predictoras serán 1, 3, 5 y 7
batch_size_valores = c(1)
units_valores = c(1,9,10)
epochs_valores = c(1)

resultados <- data.frame()

for (k in predictores) {
  
  # n contiene el numero de predictores en cada observacion (n=1 si k=1, n=9 si k=2, n=10 si k=3)
  n = switch(k,1,9,10)
  
  for (batch_size in batch_size_valores) {
    for (units in units_valores) {
      for (epochs in epochs_valores) {
        
        cat("Evaluando modelo LSTM con c:",c,"Predictores:",k,"batch_size:",batch_size,"units:",units,"epochs:",epochs,"\n")
        
        returnList <- preparar_datos(c, k)
        
        X_train <- returnList$X_train
        Y_train <- returnList$Y_train
        X_test <- returnList$X_test
        Y_test <- returnList$Y_test
          
        modelo <- crear_modelo_lstm(batch_size, units)
        entrenar_modelo_lstm(modelo = modelo, batch_size, epochs)
        Y_pred <- predicciones_modelo_lstm(modelo = modelo, batch_size)
        rmse = evaluar_modelo_lstm()
        
        resultados <- rbind(resultados, c(c,k,batch_size,units,epochs,rmse))
        colnames(resultados) <- c("c","k","batch_size","units","epochs","rmse")
        write.csv2(resultados, file = "resultados.csv", row.names= FALSE, col.names = TRUE)
        
      }
    }
  }
}

```